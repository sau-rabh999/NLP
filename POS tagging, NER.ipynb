{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('all')\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('treebank')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('sells', 'VBZ'),\n",
       " ('sea', 'NN'),\n",
       " ('shells', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sea', 'NN'),\n",
       " ('shore', 'NN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1 = 'She sells sea shells on the sea shore'\n",
    "tokens = nltk.word_tokenize(sen1)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('While', 'IN'),\n",
       " ('playing', 'VBG'),\n",
       " ('football', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('ball', 'NN'),\n",
       " ('thrown', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('friend', 'NN'),\n",
       " ('hit', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('boy', 'NN'),\n",
       " ('crossing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('street', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen2 = 'While playing football, the ball thrown by my friend hit the boy crossing the street.'\n",
    "tokens = nltk.word_tokenize(sen2)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lalitha', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('sick', 'JJ'),\n",
       " ('today', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('her', 'PRP$'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('hospital', 'NN'),\n",
       " ('now', 'RB'),\n",
       " (',', ','),\n",
       " ('before', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('gets', 'VBZ'),\n",
       " ('worse', 'JJR'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen3 = 'Lalitha is very sick today and we will take her to the hospital now, before she gets worse.'\n",
    "tokens = nltk.word_tokenize(sen3)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('race', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('near', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen3 = 'The end of the race was near.'\n",
    "tagged = nltk.pos_tag(word_tokenize(sen3))\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('end', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('race', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen4 = 'He will end the race.'\n",
    "tagged = nltk.pos_tag(word_tokenize(sen4))\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = '''The best semiconductor companies are Intel, AMD, ARM, Samsung and Apple. All of them have their offices in USA in Seattle and San Francisco. They have outsourced their work to countries such as India, China and Taiwan. Steve Jobs was the best known leader of Apple even though Tim Cooks is now the CEO. India’s prime minister Narendra Modi wants more investment from these companies to come to India. Bangalore is the hub of electronics in South India and the chief minister of Karnataka Yedurappa has invited these companies to set up their production houses in Bangalore.''' \n",
    "ne_tokens = nltk.word_tokenize(text)\n",
    "ne_tags = nltk.pos_tag(ne_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  best/JJS\n",
      "  semiconductor/NN\n",
      "  companies/NNS\n",
      "  are/VBP\n",
      "  (ORGANIZATION Intel/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION AMD/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION ARM/NNP)\n",
      "  ,/,\n",
      "  (PERSON Samsung/NNP)\n",
      "  and/CC\n",
      "  (GPE Apple/NNP)\n",
      "  ./.\n",
      "  All/DT\n",
      "  of/IN\n",
      "  them/PRP\n",
      "  have/VBP\n",
      "  their/PRP$\n",
      "  offices/NNS\n",
      "  in/IN\n",
      "  (ORGANIZATION USA/NNP)\n",
      "  in/IN\n",
      "  (GPE Seattle/NNP)\n",
      "  and/CC\n",
      "  (PERSON San/NNP Francisco/NNP)\n",
      "  ./.\n",
      "  They/PRP\n",
      "  have/VBP\n",
      "  outsourced/VBN\n",
      "  their/PRP$\n",
      "  work/NN\n",
      "  to/TO\n",
      "  countries/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  (GPE China/NNP)\n",
      "  and/CC\n",
      "  (GPE Taiwan/NNP)\n",
      "  ./.\n",
      "  (PERSON Steve/NNP Jobs/NNP)\n",
      "  was/VBD\n",
      "  the/DT\n",
      "  best/JJS\n",
      "  known/JJ\n",
      "  leader/NN\n",
      "  of/IN\n",
      "  (GPE Apple/NNP)\n",
      "  even/RB\n",
      "  though/IN\n",
      "  (PERSON Tim/NNP Cooks/NNP)\n",
      "  is/VBZ\n",
      "  now/RB\n",
      "  the/DT\n",
      "  (ORGANIZATION CEO/NNP)\n",
      "  ./.\n",
      "  (PERSON India/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  prime/JJ\n",
      "  minister/NN\n",
      "  (PERSON Narendra/NNP Modi/NNP)\n",
      "  wants/VBZ\n",
      "  more/JJR\n",
      "  investment/NN\n",
      "  from/IN\n",
      "  these/DT\n",
      "  companies/NNS\n",
      "  to/TO\n",
      "  come/VB\n",
      "  to/TO\n",
      "  (GPE India/NNP)\n",
      "  ./.\n",
      "  (PERSON Bangalore/NNP)\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  hub/NN\n",
      "  of/IN\n",
      "  electronics/NNS\n",
      "  in/IN\n",
      "  (GPE South/NNP India/NNP)\n",
      "  and/CC\n",
      "  the/DT\n",
      "  chief/JJ\n",
      "  minister/NN\n",
      "  of/IN\n",
      "  (PERSON Karnataka/NNP Yedurappa/NNP)\n",
      "  has/VBZ\n",
      "  invited/VBN\n",
      "  these/DT\n",
      "  companies/NNS\n",
      "  to/TO\n",
      "  set/VB\n",
      "  up/RP\n",
      "  their/PRP$\n",
      "  production/NN\n",
      "  houses/NNS\n",
      "  in/IN\n",
      "  (GPE Bangalore/NNP)\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk import ne_chunk\n",
    "ent = ne_chunk(ne_tags)\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Mahabharata and Ramayana are the epics of India based on true stories of ancient times. Mahabharata tells us about the very famous battle of Kurukshetra. The Bhagwat Gita is part of this great epic. Arjuna and Krishna are two among the many heroes of this epic. Ramayana contains the reason behind celebrating festivals like Dusshera and Diwali. Ramayana talks about Rama, Sita, Ravan, Hanuman and their battle of Lanka.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahabharata : GPE\n",
      "Ramayana : GPE\n",
      "India : GPE\n",
      "Mahabharata : GPE\n",
      "Kurukshetra : GPE\n",
      "Bhagwat Gita : ORGANIZATION\n",
      "Arjuna : GPE\n",
      "Krishna : PERSON\n",
      "Ramayana : GPE\n",
      "Dusshera : ORGANIZATION\n",
      "Diwali : GPE\n",
      "Ramayana : GPE\n",
      "Rama : PERSON\n",
      "Sita : PERSON\n",
      "Ravan : PERSON\n",
      "Hanuman : PERSON\n",
      "Lanka : GPE\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "for sent in nltk.sent_tokenize(text1):\n",
    "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "      if hasattr(chunk, 'label'):\n",
    "            print(' '.join(c[0] for c in chunk),':',chunk.label())\n",
    "         #print(chunk.label(), ' '.join(c[0] for c in chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Mahabharata/NNP)\n",
      "  and/CC\n",
      "  (GPE Ramayana/NNP)\n",
      "  are/VBP\n",
      "  the/DT\n",
      "  epics/NNS\n",
      "  of/IN\n",
      "  (GPE India/NNP)\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  true/JJ\n",
      "  stories/NNS\n",
      "  of/IN\n",
      "  ancient/JJ\n",
      "  times/NNS\n",
      "  ./.\n",
      "  (PERSON Mahabharata/NNP)\n",
      "  tells/VBZ\n",
      "  us/PRP\n",
      "  about/IN\n",
      "  the/DT\n",
      "  very/RB\n",
      "  famous/JJ\n",
      "  battle/NN\n",
      "  of/IN\n",
      "  (GPE Kurukshetra/NNP)\n",
      "  ./.\n",
      "  The/DT\n",
      "  (ORGANIZATION Bhagwat/NNP Gita/NNP)\n",
      "  is/VBZ\n",
      "  part/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  great/JJ\n",
      "  epic/NN\n",
      "  ./.\n",
      "  (PERSON Arjuna/NNP)\n",
      "  and/CC\n",
      "  (PERSON Krishna/NNP)\n",
      "  are/VBP\n",
      "  two/CD\n",
      "  among/IN\n",
      "  the/DT\n",
      "  many/JJ\n",
      "  heroes/NNS\n",
      "  of/IN\n",
      "  this/DT\n",
      "  epic/NN\n",
      "  ./.\n",
      "  (PERSON Ramayana/NNP)\n",
      "  contains/VBZ\n",
      "  the/DT\n",
      "  reason/NN\n",
      "  behind/IN\n",
      "  celebrating/VBG\n",
      "  festivals/NNS\n",
      "  like/IN\n",
      "  (ORGANIZATION Dusshera/NNP)\n",
      "  and/CC\n",
      "  (GPE Diwali/NNP)\n",
      "  ./.\n",
      "  Ramayana/NNP\n",
      "  talks/NNS\n",
      "  about/IN\n",
      "  (PERSON Rama/NNP)\n",
      "  ,/,\n",
      "  (PERSON Sita/NNP)\n",
      "  ,/,\n",
      "  (PERSON Ravan/NNP)\n",
      "  ,/,\n",
      "  (PERSON Hanuman/NNP)\n",
      "  and/CC\n",
      "  their/PRP$\n",
      "  battle/NN\n",
      "  of/IN\n",
      "  (GPE Lanka/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    " \n",
    "print(ne_chunk(pos_tag(word_tokenize(text1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#named entity recognition\n",
    "\n",
    "text = ''' Mahabharata, Ramayana, Bhagwat Geeta are the epics based on true stories. Mahabharata tells us about the very famous battle of Kurukshetra. The Bhagwat Gita is part of this great epic. Arjuna and Krishna are two among the many heroes of this epic. Ramayana contains the reason behind celebrating festivals like Dusshera and Diwali. Ramayana talks about Rama, Sita, Ravana, Hanuman and their battle of Lanka.''' \n",
    "ne_tokens = nltk.word_tokenize(text)\n",
    "ne_tags = nltk.pos_tag(ne_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Mahabharata/NNP)\n",
      "  ,/,\n",
      "  (GPE Ramayana/NNP)\n",
      "  ,/,\n",
      "  (PERSON Bhagwat/NNP Geeta/NNP)\n",
      "  are/VBP\n",
      "  the/DT\n",
      "  epics/NNS\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  true/JJ\n",
      "  stories/NNS\n",
      "  ./.\n",
      "  (PERSON Mahabharata/NNP)\n",
      "  tells/VBZ\n",
      "  us/PRP\n",
      "  about/IN\n",
      "  the/DT\n",
      "  very/RB\n",
      "  famous/JJ\n",
      "  battle/NN\n",
      "  of/IN\n",
      "  (GPE Kurukshetra/NNP)\n",
      "  ./.\n",
      "  The/DT\n",
      "  (ORGANIZATION Bhagwat/NNP Gita/NNP)\n",
      "  is/VBZ\n",
      "  part/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  great/JJ\n",
      "  epic/NN\n",
      "  ./.\n",
      "  (PERSON Arjuna/NNP)\n",
      "  and/CC\n",
      "  (PERSON Krishna/NNP)\n",
      "  are/VBP\n",
      "  two/CD\n",
      "  among/IN\n",
      "  the/DT\n",
      "  many/JJ\n",
      "  heroes/NNS\n",
      "  of/IN\n",
      "  this/DT\n",
      "  epic/NN\n",
      "  ./.\n",
      "  (PERSON Ramayana/NNP)\n",
      "  contains/VBZ\n",
      "  the/DT\n",
      "  reason/NN\n",
      "  behind/IN\n",
      "  celebrating/VBG\n",
      "  festivals/NNS\n",
      "  like/IN\n",
      "  (ORGANIZATION Dusshera/NNP)\n",
      "  and/CC\n",
      "  (GPE Diwali/NNP)\n",
      "  ./.\n",
      "  Ramayana/NNP\n",
      "  talks/NNS\n",
      "  about/IN\n",
      "  (PERSON Rama/NNP)\n",
      "  ,/,\n",
      "  (PERSON Sita/NNP)\n",
      "  ,/,\n",
      "  (GPE Ravana/NNP)\n",
      "  ,/,\n",
      "  (PERSON Hanuman/NNP)\n",
      "  and/CC\n",
      "  their/PRP$\n",
      "  battle/NN\n",
      "  of/IN\n",
      "  (GPE Lanka/NNP)\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk import ne_chunk\n",
    "ent = ne_chunk(ne_tags)\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSE TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('fined', 'VBD'),\n",
       " ('Google', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('$', '$'),\n",
       " ('5.1', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('abusing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mobile', 'JJ'),\n",
       " ('phone', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('alter', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('practices', 'NNS')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  European/JJ\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  Google/NNP\n",
      "  (NP a/DT record/NN)\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  (NP power/NN)\n",
      "  in/IN\n",
      "  (NP the/DT mobile/JJ phone/NN)\n",
      "  (NP market/NN)\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (NP the/DT company/NN)\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "#Our chunk pattern consists of one rule, that a noun phrase, NP, should be formed whenever the chunker finds \n",
    "#an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN.\n",
    "\n",
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'  #Using this pattern, we create a chunk parser and test it on our sentence\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)\n",
    "cs.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = \"Ashwin and Varun arrived at the station before noon ,and so I could not meet them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ashwin', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Varun', 'NNP'),\n",
       " ('arrived', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('station', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('noon', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('meet', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex2)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Ashwin/NNP\n",
      "  and/CC\n",
      "  Varun/NNP\n",
      "  arrived/VBD\n",
      "  at/IN\n",
      "  (NP the/DT station/NN)\n",
      "  before/IN\n",
      "  (NP noon/NN)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  so/RB\n",
      "  I/PRP\n",
      "  could/MD\n",
      "  not/RB\n",
      "  meet/VB\n",
      "  them/PRP\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)\n",
    "cs.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = \"If she had gone on a picnic, she would have had a lot of fun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('If', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('gone', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('picnic', 'NN'),\n",
       " (',', ','),\n",
       " ('she', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('had', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fun', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex3)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  If/IN\n",
      "  she/PRP\n",
      "  had/VBD\n",
      "  gone/VBN\n",
      "  on/IN\n",
      "  (NP a/DT picnic/NN)\n",
      "  ,/,\n",
      "  she/PRP\n",
      "  would/MD\n",
      "  have/VB\n",
      "  had/VBN\n",
      "  (NP a/DT lot/NN)\n",
      "  of/IN\n",
      "  (NP fun/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)\n",
    "cs.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "c = lesk(word_tokenize('On the face of earth'),'face')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('face.n.07') the part of an animal corresponding to the human face\n"
     ]
    }
   ],
   "source": [
    "print(c,c.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('side.n.04') a surface forming part of the outside of an object\n"
     ]
    }
   ],
   "source": [
    "cw = lesk(word_tokenize('She applied a facepack'),'face')\n",
    "print(cw,cw.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('NNP', 9410), (',', 4886), ('CD', 3546), ('NNS', 6047), ('JJ', 5834), ('MD', 927), ('VB', 2554), ('DT', 8165), ('NN', 13166), ('IN', 9857), ('.', 3874), ('VBZ', 2125), ('VBG', 1460), ('CC', 2265), ('VBD', 3043), ('VBN', 2134), ('-NONE-', 6592), ('RB', 2822), ('TO', 2179), ('PRP', 1716), ('RBR', 136), ('WDT', 445), ('VBP', 1321), ('RP', 216), ('PRP$', 766), ('JJS', 182), ('POS', 824), ('``', 712), ('EX', 88), (\"''\", 694), ('WP', 241), (':', 563), ('JJR', 381), ('WRB', 178), ('$', 724), ('NNPS', 244), ('WP$', 14), ('-LRB-', 120), ('-RRB-', 126), ('PDT', 27), ('RBS', 35), ('FW', 4), ('UH', 3), ('SYM', 1), ('LS', 13), ('#', 16)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "fd = FreqDist()\n",
    "for word, tag in treebank.tagged_words():\n",
    "    fd[tag] += 1\n",
    "fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nps_chat', 'nps_chat.zip', 'omw.zip', 'reuters.zip', 'stopwords', 'stopwords.zip', 'treebank', 'treebank.zip', 'wordnet', 'wordnet.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As', 'a', 'result', ',', 'although', 'we', 'still', ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='religion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\indian.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['पूर्ण', 'प्रतिबंध', 'हटाओ', ':', 'इराक', 'संयुक्त', ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('indian')\n",
    "nltk.corpus.indian.words('hindi.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER REDONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_er(text):\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "       for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "          if hasattr(chunk, 'label'):\n",
    "                print(' '.join(c[0] for c in chunk),':',chunk.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Mahabharata and Ramayana are the epics of India based on true stories of ancient times. Mahabharata tells us about the very famous battle of Kurukshetra. The Bhagwat Gita is part of this great epic. Arjuna and Krishna are two among the many heroes of this epic. Ramayana contains the reason behind celebrating festivals like Dusshera and Diwali. Ramayana talks about Rama , Sita, Ravan, Hanuman and their battle of Lanka.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahabharata : GPE\n",
      "Ramayana : GPE\n",
      "India : GPE\n",
      "Mahabharata : GPE\n",
      "Kurukshetra : GPE\n",
      "Bhagwat Gita : ORGANIZATION\n",
      "Arjuna : GPE\n",
      "Krishna : PERSON\n",
      "Ramayana : GPE\n",
      "Dusshera : ORGANIZATION\n",
      "Diwali : GPE\n",
      "Ramayana : GPE\n",
      "Rama : PERSON\n",
      "Sita : PERSON\n",
      "Ravan : PERSON\n",
      "Hanuman : PERSON\n",
      "Lanka : GPE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(named_er(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=\"Panasonic Corporation, the Japan based electronics company, plans to set up a new plant at Jhajjar in Haryana, which will manufacture refrigerators for the Indian market, along with setting up a research and development (R&D) center for appliances consisting of two technical divisions to strengthen the product development in the country. Samsung India Electronics Ltd has signed a deal to lease 100,000 square feet (sqft) of space at Oberoi Realty Ltd’s commercial property Commerz II in Goregaon suburb of Mumbai, for setting up its new corporate office.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panasonic : PERSON\n",
      "Corporation : ORGANIZATION\n",
      "Japan : GPE\n",
      "Jhajjar : ORGANIZATION\n",
      "Haryana : GPE\n",
      "Indian : GPE\n",
      "R : ORGANIZATION\n",
      "Samsung : PERSON\n",
      "India : GPE\n",
      "Oberoi Realty Ltd : ORGANIZATION\n",
      "Commerz : ORGANIZATION\n",
      "Goregaon : GPE\n",
      "Mumbai : GPE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(named_er(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-78d48b527458>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-78d48b527458>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    labels.append(chunk.label())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chunks = nltk.ne_chunk(pos_tag(word_tokenize(text1)))\n",
    "\n",
    "entities = []\n",
    "labels = []\n",
    "for chunk in chunks:\n",
    "    if(hasattr(chunk,'label')):\n",
    "        entities.append(' '.join(c[0] for c in chunk)\n",
    "        labels.append(chunk.label())\n",
    "\n",
    "entities_labels = list(set(zip(entities,labels)))\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = ['entities','labels']\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = '''In July 2020, Foxconn pledged to invest $1 billion (Rs7,357crore) into iPhone manufacturing in India over the next three years. Meanwhile, Wistron said it had lined up a $400 million investment into the country, a third of which it had already spent. “Our business roughly doubled.\" Apple chief executive Tim Cook said in an earnings call in January.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foxconn : PERSON\n",
      "iPhone : ORGANIZATION\n",
      "India : GPE\n",
      "Wistron : PERSON\n",
      "Apple : GPE\n",
      "Tim Cook : PERSON\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(named_er(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The best semiconductor companies are Intel, AMD, ARM ,Samsung and Apple. All of them have their offices in USA in Seattle and San Francisco. They have outsourced their work to countries such as India, China and Taiwan. Steve Jobs was the best known leader of Apple even though Tim Cooks is now the CEO. India’s prime minister Narendra Modi wants more investment from these companies to come to India. Bangalore is the hub of electronics in South India and the chief minister of Karnataka, Yedurappa has invited these companies to set up their production houses in Bangalore. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel : ORGANIZATION\n",
      "AMD : ORGANIZATION\n",
      "ARM : ORGANIZATION\n",
      "Samsung : PERSON\n",
      "Apple : GPE\n",
      "USA : ORGANIZATION\n",
      "Seattle : GPE\n",
      "San Francisco : PERSON\n",
      "India : GPE\n",
      "China : GPE\n",
      "Taiwan : GPE\n",
      "Steve : PERSON\n",
      "Jobs : PERSON\n",
      "Apple : GPE\n",
      "Tim Cooks : PERSON\n",
      "CEO : ORGANIZATION\n",
      "India : GPE\n",
      "Narendra Modi : PERSON\n",
      "India : GPE\n",
      "Bangalore : GPE\n",
      "South India : GPE\n",
      "Karnataka : GPE\n",
      "Yedurappa : PERSON\n",
      "Bangalore : GPE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(named_er(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
